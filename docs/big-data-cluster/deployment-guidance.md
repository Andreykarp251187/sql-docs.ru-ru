---
title: Руководства по развертыванию
titleSuffix: SQL Server big data clusters
description: Узнайте, как развернуть кластеры больших данных SQL Server 2019 (Предварительная версия) в Kubernetes.
author: MikeRayMSFT
ms.author: mikeray
ms.reviewer: mihaelab
ms.date: 07/24/2019
ms.topic: conceptual
ms.prod: sql
ms.technology: big-data-cluster
ms.openlocfilehash: e6f2eefd37c45753e3051722448b80d88712df26
ms.sourcegitcommit: 1f222ef903e6aa0bd1b14d3df031eb04ce775154
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/23/2019
ms.locfileid: "68419417"
---
# <a name="how-to-deploy-sql-server-big-data-clusters-on-kubernetes"></a>Развертывание SQL Server кластеров больших данных в Kubernetes

[!INCLUDE[tsql-appliesto-ssver15-xxxx-xxxx-xxx](../includes/tsql-appliesto-ssver15-xxxx-xxxx-xxx.md)]

SQL Server кластер больших данных развертывается в виде контейнеров DOCKER в кластере Kubernetes. Ниже приведены общие сведения о настройке и настройке.

- Настройте кластер Kubernetes на одной виртуальной машине, кластере виртуальных машин или в службе Kubernetes Azure (AKS).
- Установите средство настройки кластера **аздата** на клиентском компьютере.
- Развертывание SQL Server кластера больших данных в кластере Kubernetes.

[!INCLUDE [Limited public preview note](../includes/big-data-cluster-preview-note.md)]

## <a name="install-sql-server-2019-big-data-tools"></a>Установка средств для обработки больших данных SQL Server 2019

Перед развертыванием кластера больших данных SQL Server 2019 сначала [установите инструменты для обработки больших данных](deploy-big-data-tools.md):

- **аздата**
- **kubectl**
- **Azure Data Studio**
- **Расширение SQL Server 2019**

## <a id="prereqs"></a>Предварительные требования для Kubernetes

Для SQL Server кластеров больших данных требуется минимальная Kubernetes версия не менее версии 1.10 для сервера и клиента (kubectl).

> [!NOTE]
> Обратите внимание, что версии клиента и сервера Kubernetes должны быть в пределах + 1 или-1 дополнительной версии. Дополнительные сведения см. в статьях [заметки о выпуске Kubernetes и политика SKU отклонение версий](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/release/versioning.md#supported-releases-and-component-skew).

### <a id="kubernetes"></a>Установка кластера Kubernetes

Если у вас уже есть кластер Kubernetes, соответствующий приведенным выше предварительным требованиям, можно сразу перейти к [этапу развертывания](#deploy). В этом разделе предполагается базовое понимание концепций Kubernetes.  Подробные сведения о Kubernetes см. в [документации по Kubernetes](https://kubernetes.io/docs/home).

Вы можете развернуть Kubernetes любым из трех способов:

| Развертывание Kubernetes на: | Описание | Ссылка |
|---|---|---|
| **Службы Azure Kubernetes Services (AKS)** | Управляемая служба контейнеров Kubernetes в Azure. | [Водим](deploy-on-aks.md) |
| **Несколько компьютеров (кубеадм)** | Кластер Kubernetes, развернутый на физических компьютерах или виртуальных машинах с помощью **кубеадм** | [Водим](deploy-with-kubeadm.md) |
| **Minikube** | Кластер Kubernetes с одним узлом в виртуальной машине. | [Водим](deploy-on-minikube.md) |

> [!TIP]
> Пример сценария Python, который развертывает AKS и SQL Server кластер больших данных за один шаг, см. в разделе [краткое руководство. Развертывание SQL Server кластера больших данных в службе Azure Kubernetes (AKS)](quickstart-big-data-cluster-deploy.md).

### <a name="verify-kubernetes-configuration"></a>Проверка конфигурации Kubernetes

Выполните команду **kubectl** , чтобы просмотреть конфигурацию кластера. Убедитесь, что kubectl указывает на правильный контекст кластера.

```bash
kubectl config view
```

После настройки кластера Kubernetes можно продолжить развертывание нового кластера больших данных SQL Server. Если вы обновляете предыдущую версию, см. статью [обновление SQL Server кластеров больших данных](deployment-upgrade.md).

## <a id="deploy"></a>Общие сведения о развертывании

Большинство параметров кластера больших данных определяются в файле конфигурации развертывания JSON. Можно использовать профиль развертывания по умолчанию для AKS, `kubeadm`или `minikube` , или можно настроить собственный файл конфигурации развертывания для использования во время установки. По соображениям безопасности параметры проверки подлинности передаются через переменные среды.

В следующих разделах содержатся дополнительные сведения о настройке развертываний кластера больших данных, а также примеры распространенных настроек. Кроме того, вы всегда можете изменить файл конфигурации пользовательского развертывания, используя редактор, например VS Code.

## <a id="configfile"></a>Конфигурации по умолчанию

Параметры развертывания кластера больших данных определяются в файлах конфигурации JSON. Существует три стандартных профиля развертывания с параметрами по умолчанию для сред разработки и тестирования:

| Профиль развертывания | Среда Kubernetes |
|---|---|
| **AKS-dev-test** | Служба Kubernetes Azure (AKS) |
| **кубеадм-dev-test** | Несколько компьютеров (кубеадм) |
| **minikube-dev-test** | Minikube |

Кластер больших данных можно развернуть, запустив **аздата BDC Create**. Будет предложено выбрать одну из конфигураций по умолчанию, а затем выполнить развертывание.

При первом запуске `azdata` необходимо включить `--accept-eula` , чтобы принять условия лицензионного соглашения (EULA).

```bash
azdata bdc create --accept-eula
```

В этом случае вам будет предложено ввести параметры, не входящие в конфигурацию по умолчанию, например пароли. 

> [!NOTE]
> Начиная с версии SQL Server 2019 CTP 3,2, вы больше не должны быть участником [программы раннего перехода](https://aka.ms/eapsignup) SQL Server 2019, чтобы получить доступ к предварительным выпускам кластера больших данных.

> [!IMPORTANT]
> По умолчанию для кластера больших данных используется имя **MSSQL-Cluster**. Это важно для того, чтобы выполнить любую из команд **kubectl** , задающих пространство имен Kubernetes с `-n` параметром.

## <a id="customconfig"></a>Пользовательские конфигурации

Также можно настроить собственный профиль конфигурации развертывания. Это можно сделать, выполнив следующие действия.

1. Начните с одного из стандартных профилей развертывания, соответствующих среде Kubernetes. Для их перечисления можно использовать команду **аздата BDC config list** :

   ```bash
   azdata bdc config list
   ```

1. Чтобы настроить развертывание, создайте копию профиля развертывания с помощью команды **аздата BDC config init** . Например, следующая команда создает копию файлов конфигурации развертывания **AKS-dev-test** в целевом каталоге с именем `custom`:

   ```bash
   azdata bdc config init --source aks-dev-test --target custom
   ```

   аздата
   > Указывает каталог, содержащий файлы конфигурации **cluster. JSON** и `--source` **Control. JSON**на основе параметра. `--target`

1. Чтобы настроить параметры в профиле конфигурации развертывания, можно изменить файл конфигурации развертывания в средстве, которое подходит для редактирования JSON-файлов, например VS Code. Для автоматизации на основе скриптов можно также изменить пользовательский профиль развертывания с помощью команды **аздата BDC config** . Например, следующая команда изменяет пользовательский профиль развертывания, чтобы изменить имя развернутого кластера с по умолчанию (**MSSQL-Cluster**) на **Test-Cluster**:  

   ```bash
   azdata bdc config replace --config-file custom/cluster.json --json-values "metadata.name=test-cluster"
   ```

   > Полезным инструментом для поиска путей JSON является JSONPathный [Интерактивный оценщик](https://jsonpath.com/).

   Помимо передачи пар "ключ-значение" можно также предоставлять встроенные значения JSON или передавать файлы исправления JSON. Дополнительные сведения см. в статье [Настройка параметров развертывания для кластеров больших данных](deployment-custom-configuration.md).

1. Затем передайте пользовательский файл конфигурации в **аздата BDC Create**. Обратите внимание, что необходимо задать необходимые [переменные среды](#env), в противном случае будет предложено ввести значения:

   ```bash
   azdata bdc create --config-profile custom --accept-eula yes
   ```

> Дополнительные сведения о структуре файла конфигурации развертывания см. в разделе [ссылка на файл конфигурации развертывания](reference-deployment-config.md). Дополнительные примеры конфигурации см. в статье [Настройка параметров развертывания для кластеров больших данных](deployment-custom-configuration.md).

## <a id="env"></a>Переменные среды

Следующие переменные среды используются для параметров безопасности, которые не хранятся в файле конфигурации развертывания. Обратите внимание, что параметры DOCKER, кроме учетных данных, можно задать в файле конфигурации.

| Переменная среды | Требование |Описание |
|---|---|---|
| **CONTROLLER_USERNAME** | Обязательно |Имя пользователя для администратора кластера. |
| **CONTROLLER_PASSWORD** | Обязательно |Пароль для администратора кластера. |
| **MSSQL_SA_PASSWORD** | Обязательно |Пароль пользователя SA для главного экземпляра SQL. |
| **KNOX_PASSWORD** | Обязательно |Пароль для пользователя Knox. |
| **ACCEPT_EULA**| Требуется для первого использования`azdata`| Не требует значения. При задании в качестве переменной среды лицензионное соглашение применяется как к SQL Server `azdata`, так и к. Если значение не задано в качестве переменной среды, `--accept-eula` можно включить при первом `azdata` использовании команды.|
| **DOCKER_USERNAME** | Необязательно | Имя пользователя для доступа к образам контейнера в случае, если они хранятся в частном репозитории. Дополнительные сведения о том, как использовать частный репозиторий DOCKER для развертывания больших кластеров данных, см. в разделе [автономные развертывания](deploy-offline.md) .|
| **DOCKER_PASSWORD** | Необязательно |Пароль для доступа к указанному выше частному репозиторию. |

Эти переменные среды должны быть установлены перед вызовом **аздата BDC Create**. Если какая-либо из переменных не задана, вам будет предложено ввести ее.

В следующем примере показано, как задать переменные среды для Linux (bash) и Windows (PowerShell):

```bash
export CONTROLLER_USERNAME=admin
export CONTROLLER_PASSWORD=<password>
export MSSQL_SA_PASSWORD=<password>
export KNOX_PASSWORD=<password>
```

```PowerShell
SET CONTROLLER_USERNAME=admin
SET CONTROLLER_PASSWORD=<password>
SET MSSQL_SA_PASSWORD=<password>
SET KNOX_PASSWORD=<password>
```

После установки переменных среды необходимо запустить `azdata bdc create` , чтобы активировать развертывание. В этом примере используется профиль конфигурации кластера, созданный ранее.

```bash
azdata bdc create --config-profile custom --accept-eula yes
```

Обратите внимание на следующие рекомендации.

- Убедитесь, что пароль заключен в двойные кавычки, если он содержит специальные символы. Вы можете задать для **MSSQL_SA_PASSWORD** любое значение, но убедитесь, что пароль достаточно сложен и не использует `!`символы, `&` или `'` . Обратите внимание, что разделители в двойных кавычках работают только в командах bash.
- Имя входа **SA** является системным администратором экземпляра SQL Server master, который создается во время установки. После создания контейнера SQL Server можно обнаружить указанную переменную среды **MSSQL_SA_PASSWORD** , запустив `echo $MSSQL_SA_PASSWORD` ее в контейнере. В целях безопасности измените пароль SA согласно рекомендациям, описанным [здесь](../linux/quickstart-install-connect-docker.md#sapassword).

## <a id="unattended"></a>Автоматическая установка

Для автоматического развертывания необходимо задать все необходимые переменные среды, использовать файл конфигурации и вызвать `azdata bdc create` команду `--accept-eula yes` с параметром. Примеры в предыдущем разделе демонстрируют синтаксис для автоматической установки.

## <a id="monitor"></a>Мониторинг развертывания

Во время начальной загрузки кластера командное окно клиента выводит состояние развертывания. В процессе развертывания вы увидите ряд сообщений, в которых он ожидает модуль контроллера:

```output
Waiting for cluster controller to start.
```

В течение 15 – 30 минут следует уведомить о том, что модуль контроллера работает:

```output
Cluster controller endpoint is available at 11.111.111.11:30080.
Cluster control plane is ready.
```

> [!IMPORTANT]
> Полное развертывание может занять много времени из-за времени, необходимого для загрузки образов контейнеров для компонентов кластера больших данных. Однако это не должно занять несколько часов. При возникновении проблем с развертыванием см. статью [мониторинг и устранение неполадок SQL Server кластеров больших данных](cluster-troubleshooting-commands.md).

После завершения развертывания выходные данные будут уведомлены об успешном выполнении:

```output
Cluster deployed successfully.
```

> [!TIP]
> Имя по умолчанию для развернутого кластера больших `mssql-cluster` данных, если оно не изменено настраиваемой конфигурацией.

## <a id="endpoints"></a>Получение конечных точек

После успешного завершения скрипта развертывания можно получить IP-адреса внешних конечных точек для кластера больших данных, выполнив следующие действия.

1. После развертывания найдите IP-адрес конечной точки контроллера либо из стандартного выхода развертывания, либо путем просмотра выходных данных внешнего IP-адреса следующей команды **kubectl** :

   ```bash
   kubectl get svc controller-svc-external -n <your-big-data-cluster-name>
   ```

   > [!TIP]
   > Если вы не изменили имя по умолчанию во время развертывания `-n mssql-cluster` , используйте в предыдущей команде. **MSSQL-Cluster** — это имя по умолчанию для кластера больших данных.

1. Войдите в кластер больших данных с помощью [аздата login](reference-azdata.md). Задайте для параметра **--Controller-Endpoint** значение внешнего IP-адреса конечной точки контроллера.

   ```bash
   azdata login --controller-endpoint https://<ip-address-of-controller-svc-external>:30080 --controller-username <user-name>
   ```

   Укажите имя пользователя и пароль, настроенные для контроллера (CONTROLLER_USERNAME и CONTROLLER_PASSWORD) во время развертывания.

1. Запустите [список конечных точек BDC аздата](reference-azdata-bdc-endpoint.md) , чтобы получить список с описанием каждой конечной точки и соответствующими значениями IP-адреса и порта. 

   ```bash
   azdata bdc endpoint list -o table
   ```

   В следующем списке показан пример выходных данных этой команды:

   ```output
   Description                                             Endpoint                                                   Ip              Name               Port    Protocol
   ------------------------------------------------------  ---------------------------------------------------------  --------------  -----------------  ------  ----------
   Gateway to access HDFS files, Spark                     https://11.111.111.111:30443                               11.111.111.111  gateway            30443   https
   Spark Jobs Management and Monitoring Dashboard          https://11.111.111.111:30443/gateway/default/sparkhistory  11.111.111.111  spark-history      30443   https
   Spark Diagnostics and Monitoring Dashboard              https://11.111.111.111:30443/gateway/default/yarn          11.111.111.111  yarn-ui            30443   https
   Application Proxy                                       https://11.111.111.111:30778                               11.111.111.111  app-proxy          30778   https
   Management Proxy                                        https://11.111.111.111:30777                               11.111.111.111  mgmtproxy          30777   https
   Log Search Dashboard                                    https://11.111.111.111:30777/kibana                        11.111.111.111  logsui             30777   https
   Metrics Dashboard                                       https://11.111.111.111:30777/grafana                       11.111.111.111  metricsui          30777   https
   Cluster Management Service                              https://11.111.111.111:30080                               11.111.111.111  controller         30080   https
   SQL Server Master Instance Front-End                    11.111.111.111,31433                                       11.111.111.111  sql-server-master  31433   tcp
   HDFS File System Proxy                                  https://11.111.111.111:30443/gateway/default/webhdfs/v1    11.111.111.111  webhdfs            30443   https
   Proxy for running Spark statements, jobs, applications  https://11.111.111.111:30443/gateway/default/livy/v1       11.111.111.111  livy               30443   https
   ```

Вы также можете получить все конечные точки службы, развернутые для кластера, выполнив следующую команду **kubectl** :

```bash
kubectl get svc -n <your-big-data-cluster-name>
```

### <a name="minikube"></a>Minikube

При использовании minikube необходимо выполнить следующую команду, чтобы получить IP-адрес, к которому необходимо подключиться. В дополнение к IP-адресу укажите порт для конечной точки, к которой необходимо подключиться.

```bash
minikube ip
```

## <a id="status"></a>Проверка состояния кластера

После развертывания можно проверить состояние кластера с помощью команды [аздата BDC Status-демонстрация](reference-azdata-bdc-status.md) .

```bash
azdata bdc status show -o table
```

> [!TIP]
> Чтобы выполнить команды состояния, необходимо сначала войти в систему с помощью команды **аздата login** , которая была показана в разделе предыдущих конечных точек.

Ниже приведен пример выходных данных этой команды:

```output
Kind     Name           State
-------  -------------  -------
BDC      mssql-cluster  Ready
Control  default        Ready
Master   default        Ready
Compute  default        Ready
Data     default        Ready
Storage  default        Ready
```

В это состояние сводки можно также получить более подробное состояние с помощью следующих команд:

- [состояние элемента управления BDC аздата](reference-azdata-bdc-control-status.md)
- [Состояние пула BDC аздата](reference-azdata-bdc-pool-status.md)

Выходные данные этих команд содержат URL-адреса панелей мониторинга Kibana и Grafana для более подробного анализа.

В дополнение к использованию **аздата**можно также использовать Azure Data Studio для поиска конечных точек и сведений о состоянии. Дополнительные сведения о просмотре состояния кластера с помощью **аздата** и Azure Data Studio см. в разделе [Просмотр состояния кластера больших данных](view-cluster-status.md).

## <a id="connect"></a>Подключение к кластеру

Дополнительные сведения о подключении к кластеру больших данных см. в разделе [Подключение к SQL Server кластеру больших данных с помощью Azure Data Studio](connect-to-big-data-cluster.md).

## <a name="next-steps"></a>Следующие шаги

Дополнительные сведения о развертывании кластера больших данных см. в следующих ресурсах:

- [Настройка параметров развертывания для кластеров больших данных](deployment-custom-configuration.md)
- [Выполнение автономного развертывания SQL Server кластера больших данных](deploy-offline.md)
- [Обсуждения Архитектура кластеров больших данных Microsoft SQL Server](https://github.com/Microsoft/sqlworkshops/tree/master/sqlserver2019bigdataclusters)
