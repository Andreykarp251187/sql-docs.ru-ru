---
title: Руководства по развертыванию
titleSuffix: SQL Server big data clusters
description: Сведения о развертывании кластеров больших данных SQL Server 2019 (предварительная версия) в Kubernetes.
author: MikeRayMSFT
ms.author: mikeray
ms.reviewer: mihaelab
ms.date: 07/24/2019
ms.topic: conceptual
ms.prod: sql
ms.technology: big-data-cluster
ms.openlocfilehash: b7439fdc93f04ad137b0bb65269b9767d8281798
ms.sourcegitcommit: 58f1d5498c87bfe0f6ec4fd9d7bbe723be47896b
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/13/2019
ms.locfileid: "68995836"
---
# <a name="how-to-deploy-sql-server-big-data-clusters-on-kubernetes"></a>Развертывание кластеров больших данных SQL Server в Kubernetes

[!INCLUDE[tsql-appliesto-ssver15-xxxx-xxxx-xxx](../includes/tsql-appliesto-ssver15-xxxx-xxxx-xxx.md)]

Кластер больших данных SQL Server развертывается в виде контейнеров Docker в кластере Kubernetes. Здесь описаны этапы настройки.

- Настройте кластер Kubernetes на одной виртуальной машине, в кластере виртуальных машин или в службе Azure Kubernetes (AKS).
- Установите средство настройки кластера **azdata** на клиентском компьютере.
- Разверните кластер больших данных SQL Server в кластере Kubernetes.

[!INCLUDE [Limited public preview note](../includes/big-data-cluster-preview-note.md)]

## <a name="install-sql-server-2019-big-data-tools"></a>Установка средств для работы с большими данными SQL Server 2019

Перед развертыванием кластера больших данных SQL Server 2019 [установите средства для работы с большими данными](deploy-big-data-tools.md).

- **azdata**
- **kubectl**
- **Azure Data Studio**
- **Расширение SQL Server 2019**

## <a id="prereqs"></a> Предварительные требования для Kubernetes

Кластерам больших данных SQL Server требуется минимальная версия Kubernetes не ниже 1.10 для сервера и клиента (kubectl).

> [!NOTE]
> Обратите внимание, что версии клиента и сервера Kubernetes должны находиться в пределах +/– 1 от дополнительного номера версии. Дополнительные сведения см. в [заметках о выпуске Kubernetes и описании политики в отношении отклонения версий SKU](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/release/versioning.md#supported-releases-and-component-skew).

### <a id="kubernetes"></a> Настройка кластера Kubernetes

Если у вас уже есть кластер Kubernetes, соответствующий приведенным выше предварительным требованиям, можно сразу перейти к [этапу развертывания](#deploy). В этом разделе предполагается базовое понимание концепций Kubernetes.  Подробные сведения о Kubernetes см. в [документации по Kubernetes](https://kubernetes.io/docs/home).

Вы можете развернуть Kubernetes любым из трех способов.

| Расположение развертывания Kubernetes | Описание | Ссылка |
|---|---|---|
| **Службы Azure Kubernetes (AKS)** | Управляемая служба контейнеров Kubernetes в Azure. | [Инструкции](deploy-on-aks.md) |
| **Несколько компьютеров (kubeadm)** | Кластер Kubernetes, развернутый на физических компьютерах или виртуальных машинах с помощью **kubeadm** | [Инструкции](deploy-with-kubeadm.md) |
| **Minikube** | Кластер Kubernetes с одним узлом на виртуальной машине | [Инструкции](deploy-on-minikube.md) |

> [!TIP]
> Вы также можете создать скрипт для развертывания AKS и кластера больших данных за один шаг. Дополнительные сведения о том, как это сделать, см. в [скрипте Python](quickstart-big-data-cluster-deploy.md) или в [записной книжке](deploy-notebooks.md) Azure Data Studio.

### <a name="verify-kubernetes-configuration"></a>Проверка конфигурации Kubernetes

Выполните команду **kubectl**, чтобы просмотреть конфигурацию кластера. Убедитесь, что kubectl указывает на правильный контекст кластера.

```bash
kubectl config view
```

После настройки кластера Kubernetes можно перейти к развертыванию нового кластера больших данных SQL Server. Если вы обновляете предыдущий выпуск, см. статью [Обновление кластеров больших данных SQL Server](deployment-upgrade.md).

## <a id="deploy"></a> Общие сведения о развертывании

Большинство параметров кластера больших данных определяется в файле конфигурации развертывания JSON. Вы можете использовать профиль развертывания по умолчанию для AKS, `kubeadm`или `minikube`, или настроить собственный файл конфигурации развертывания для использования во время установки. По соображениям безопасности параметры проверки подлинности передаются через переменные среды.

Следующие разделы содержат дополнительные сведения о настройке развертываний кластера больших данных, а также примеры распространенных настроек. Кроме того, вы всегда можете изменить пользовательский файл конфигурации развертывания в редакторе, таком как VS Code.

## <a id="configfile"></a> Конфигурации по умолчанию

Параметры развертывания кластера больших данных определяются в файлах конфигурации JSON. Существует три стандартных профиля развертывания с параметрами по умолчанию для сред разработки и тестирования.

| Профиль развертывания | Среда Kubernetes |
|---|---|
| **aks-dev-test** | Служба Azure Kubernetes (AKS) |
| **kubeadm-dev-test** | Несколько компьютеров (kubeadm) |
| **minikube-dev-test** | minikube |

Кластер больших данных можно развернуть, выполнив **azdata bdc create**. Вам будет предложено выбрать одну из конфигураций по умолчанию, а затем выполнить развертывание, следуя указаниям.

При первом запуске `azdata` нужно включить `--accept-eula=yes`, чтобы принять условия лицензионного соглашения (EULA).

```bash
azdata bdc create --accept-eula=yes
```

В этом сценарии вам будет предложено ввести параметры, не входящие в конфигурацию по умолчанию, например пароли. 

> [!IMPORTANT]
> Имя кластера больших данных по умолчанию — **mssql-cluster**. Это важно знать, чтобы выполнить любую из команд **kubectl**, задающих пространство имен Kubernetes с параметром `-n`.

## <a id="customconfig"></a> Пользовательские конфигурации

Можно также настроить собственный профиль конфигурации развертывания. Для этого выполните следующие действия.

1. Начните с одного из стандартных профилей развертывания, соответствующих вашей среде Kubernetes. Для их перечисления можно использовать команду **azdata bdc config list**.

   ```bash
   azdata bdc config list
   ```

1. Чтобы настроить развертывание, создайте копию профиля развертывания с помощью команды **azdata bdc config init**. Например, следующая команда создает копию файлов конфигурации развертывания **aks-dev-test** в целевом каталоге `custom`.

   ```bash
   azdata bdc config init --source aks-dev-test --target custom
   ```

   azdata
   > `--target` указывает каталог, содержащий файлы конфигурации **cluster.json** и **control.json**, на основе параметра `--source`.

1. Чтобы настроить параметры в профиле конфигурации развертывания, можно изменить этот файл в средстве, которое подходит для редактирования JSON-файлов, например VS Code. Для автоматизации на основе скриптов можно также изменить пользовательский профиль развертывания с помощью команды **azdata bdc config**. Например, следующая команда изменяет пользовательский профиль развертывания, чтобы изменить имя развернутого кластера с используемого по умолчанию (**mssql-cluster**) на **test-cluster**.  

   ```bash
   azdata bdc config replace --config-file custom/cluster.json --json-values "metadata.name=test-cluster"
   ```
   
> [!TIP]
> Вы также можете передать имя кластера во время развертывания с помощью параметра *--name* для команды *azdata create bdc*. Параметры в команде имеют приоритет над значениями в файлах конфигурации.

   > Полезным инструментом для поиска путей JSON является [JSONPath Online Evaluator](https://jsonpath.com/).

   Кроме передачи пар "ключ — значение", можно также указать встроенные значения JSON или передать файлы исправлений JSON. Дополнительные сведения см. в статье [Настройка параметров развертывания для кластеров больших данных](deployment-custom-configuration.md).

1. Затем передайте пользовательский файл конфигурации в **azdata bdc create**. Обратите внимание, что требуется задать необходимые [переменные среды](#env), в противном случае вам будет предложено ввести значения:

   ```bash
   azdata bdc create --config-profile custom --accept-eula yes
   ```

> Дополнительные сведения о структуре файла конфигурации развертывания см. в [справочнике по файлу конфигурации развертывания](reference-deployment-config.md). Дополнительные примеры конфигурации см. в статье [Настройка параметров развертывания для кластеров больших данных](deployment-custom-configuration.md).

## <a id="env"></a> Переменные среды

Указанные ниже переменные среды используются для параметров безопасности, которые не хранятся в файле конфигурации развертывания. Обратите внимание, что параметры Docker, за исключением учетных данных, можно задать в файле конфигурации.

| Переменная среды | Требование |Описание |
|---|---|---|
| **CONTROLLER_USERNAME** | Обязательно |Имя пользователя для администратора кластера. |
| **CONTROLLER_PASSWORD** | Обязательно |Пароль для администратора кластера. |
| **MSSQL_SA_PASSWORD** | Обязательно |Пароль пользователя SA (с правами системного администратора) для главного экземпляра SQL. |
| **KNOX_PASSWORD** | Обязательно |Пароль пользователя Knox. |
| **ACCEPT_EULA**| Требуется для первого использования `azdata`.| Никакое значение не требуется. При задании в качестве переменной среды применяет лицензионное соглашение как к SQL Server, так и к `azdata`. Если параметр не задан в качестве переменной среды, можно включить `--accept-eula` при первом использовании команды `azdata`.|
| **DOCKER_USERNAME** | Необязательно | Имя пользователя для доступа к образам контейнера в случае, если они хранятся в частном репозитории. Дополнительные сведения о том, как использовать частный репозиторий Docker для развертывания кластеров больших данных, см. в разделе [Автономные развертывания](deploy-offline.md).|
| **DOCKER_PASSWORD** | Необязательно |Пароль для доступа к указанному выше частному репозиторию. |

Эти переменные среды должны быть заданы до вызова **azdata bdc create**. Если какая-либо из переменных не задана, вам будет предложено ввести ее.

В следующем примере показано, как задать переменные среды для Linux (bash) и Windows (PowerShell).

```bash
export CONTROLLER_USERNAME=admin
export CONTROLLER_PASSWORD=<password>
export MSSQL_SA_PASSWORD=<password>
export KNOX_PASSWORD=<password>
```

```PowerShell
SET CONTROLLER_USERNAME=admin
SET CONTROLLER_PASSWORD=<password>
SET MSSQL_SA_PASSWORD=<password>
SET KNOX_PASSWORD=<password>
```

После задания переменных среды нужно запустить `azdata bdc create`, чтобы активировать развертывание. В этом примере используется профиль конфигурации кластера, созданный ранее.

```bash
azdata bdc create --config-profile custom --accept-eula yes
```

Нужно учитывать следующее.

- Заключите пароль в двойные кавычки, если он содержит специальные символы. Вы можете задать для **MSSQL_SA_PASSWORD** любое значение, но убедитесь, что пароль достаточно сложен и не содержит символы `!`, `&` или `'`. Обратите внимание, что разделители в виде двойных кавычек работают только в командах bash.
- Учетная запись **SA** обладает правами системного администратора на главном экземпляре SQL Server, создаваемом во время установки. После создания контейнера SQL Server указанную вами переменную среды **MSSQL_SA_PASSWORD** можно обнаружить, запустив `echo $MSSQL_SA_PASSWORD` в контейнере. В целях безопасности смените пароль SA, как описано [здесь](../linux/quickstart-install-connect-docker.md#sapassword).

## <a id="unattended"></a> Автоматическая установка

Для автоматического развертывания нужно задать все необходимые переменные среды, использовать файл конфигурации и вызвать команду `azdata bdc create` с параметром `--accept-eula yes`. Примеры в предыдущем разделе демонстрируют синтаксис для автоматической установки.

## <a id="monitor"></a> Мониторинг развертывания

Во время начальной загрузки кластера командное окно клиента выводит состояние развертывания. В процессе развертывания вы увидите ряд сообщений об ожидании pod контроллера.

```output
Waiting for cluster controller to start.
```

В течение 15–30 минут вы должны получить уведомление о том, что pod контроллера работает.

```output
Cluster controller endpoint is available at 11.111.111.11:30080.
Cluster control plane is ready.
```

> [!IMPORTANT]
> Полное развертывание может занять много времени из-за временных затрат на скачивание образов контейнеров для компонентов кластера больших данных. Однако это не должно занять несколько часов. При возникновении проблем с развертыванием см. статью [Мониторинг и устранение неполадок кластеров больших данных SQL Server](cluster-troubleshooting-commands.md).

После завершения развертывания выходные данные указывают на успешное выполнение.

```output
Cluster deployed successfully.
```

> [!TIP]
> Именем по умолчанию для развернутого кластера больших данных является `mssql-cluster`, если только оно не изменено в пользовательской конфигурации.

## <a id="endpoints"></a> Получение конечных точек

После успешного завершения скрипта развертывания можно получить IP-адреса внешних конечных точек для кластера больших данных, выполнив указанные ниже действия.

1. После развертывания найдите IP-адрес конечной точки контроллера либо в стандартных выходных данных развертывания, либо в выходных данных EXTERNAL-IP следующей команды **kubectl**.

   ```bash
   kubectl get svc controller-svc-external -n <your-big-data-cluster-name>
   ```

   > [!TIP]
   > Если вы не изменили имя по умолчанию во время развертывания, используйте `-n mssql-cluster` в предыдущей команде. **mssql-cluster** — это имя по умолчанию для кластера больших данных.

1. Войдите в кластер больших данных с помощью [azdata login](reference-azdata.md). Задайте для параметра **--controller-endpoint** значение внешнего IP-адреса конечной точки контроллера.

   ```bash
   azdata login --controller-endpoint https://<ip-address-of-controller-svc-external>:30080 --controller-username <user-name>
   ```

   Укажите имя пользователя и пароль, настроенные для контроллера (CONTROLLER_USERNAME и CONTROLLER_PASSWORD) во время развертывания.

1. Выполните команду [azdata bdc endpoint list](reference-azdata-bdc-endpoint.md), чтобы получить список с описанием каждой конечной точки и соответствующими значениями IP-адреса и порта. 

   ```bash
   azdata bdc endpoint list -o table
   ```

   Следующий список содержит пример выходных данных этой команды.

   ```output
   Description                                             Endpoint                                                   Ip              Name               Port    Protocol
   ------------------------------------------------------  ---------------------------------------------------------  --------------  -----------------  ------  ----------
   Gateway to access HDFS files, Spark                     https://11.111.111.111:30443                               11.111.111.111  gateway            30443   https
   Spark Jobs Management and Monitoring Dashboard          https://11.111.111.111:30443/gateway/default/sparkhistory  11.111.111.111  spark-history      30443   https
   Spark Diagnostics and Monitoring Dashboard              https://11.111.111.111:30443/gateway/default/yarn          11.111.111.111  yarn-ui            30443   https
   Application Proxy                                       https://11.111.111.111:30778                               11.111.111.111  app-proxy          30778   https
   Management Proxy                                        https://11.111.111.111:30777                               11.111.111.111  mgmtproxy          30777   https
   Log Search Dashboard                                    https://11.111.111.111:30777/kibana                        11.111.111.111  logsui             30777   https
   Metrics Dashboard                                       https://11.111.111.111:30777/grafana                       11.111.111.111  metricsui          30777   https
   Cluster Management Service                              https://11.111.111.111:30080                               11.111.111.111  controller         30080   https
   SQL Server Master Instance Front-End                    11.111.111.111,31433                                       11.111.111.111  sql-server-master  31433   tcp
   HDFS File System Proxy                                  https://11.111.111.111:30443/gateway/default/webhdfs/v1    11.111.111.111  webhdfs            30443   https
   Proxy for running Spark statements, jobs, applications  https://11.111.111.111:30443/gateway/default/livy/v1       11.111.111.111  livy               30443   https
   ```

Вы также можете получить все конечные точки службы, развернутые для кластера, выполнив следующую команду **kubectl**.

```bash
kubectl get svc -n <your-big-data-cluster-name>
```

### <a name="minikube"></a>Minikube

При использовании minikube нужно выполнить приведенную ниже команду, чтобы получить IP-адрес, к которому требуется подключиться. Кроме IP-адреса, укажите порт для конечной точки, к которой требуется подключиться.

```bash
minikube ip
```

## <a id="status"></a> Проверка состояния кластера

После развертывания можно проверить состояние кластера с помощью команды [azdata bdc status show](reference-azdata-bdc-status.md).

```bash
azdata bdc status show -o table
```

> [!TIP]
> Чтобы выполнить команды состояния, нужно сначала войти в систему с помощью команды **azdata login**, которая была приведена в предыдущем разделе о конечных точках.

Ниже приведен пример выходных данных этой команды.

```output
Kind     Name           State
-------  -------------  -------
BDC      mssql-cluster  Ready
Control  default        Ready
Master   default        Ready
Compute  default        Ready
Data     default        Ready
Storage  default        Ready
```

В этом состоянии сводки можно также получить более подробные сведения о состоянии с помощью следующих команд.

- [azdata bdc control status](reference-azdata-bdc-control-status.md)
- [azdata bdc pool status](reference-azdata-bdc-pool-status.md)

Выходные данные этих команд содержат URL-адреса панелей мониторинга Kibana и Grafana для более подробного анализа.

В дополнение к использованию **azdata** можно также использовать Azure Data Studio для поиска конечных точек и сведений о состоянии. Дополнительные сведения о просмотре состояния кластера с помощью **azdata** и Azure Data Studio см. в статье [Просмотр состояния кластера больших данных](view-cluster-status.md).

## <a id="connect"></a> Подключение к кластеру

Дополнительные сведения о подключении к кластеру больших данных см. в статье [Подключение к кластеру больших данных SQL Server с помощью Azure Data Studio](connect-to-big-data-cluster.md).

## <a name="next-steps"></a>Следующие шаги

Дополнительные сведения о развертывании кластера больших данных см. в следующих статьях.

- [Настройка параметров развертывания для кластеров больших данных](deployment-custom-configuration.md)
- [Выполнение автономного развертывания кластера больших данных SQL Server](deploy-offline.md)
- [Семинар. Архитектура кластеров больших данных Microsoft SQL Server](https://github.com/Microsoft/sqlworkshops/tree/master/sqlserver2019bigdataclusters)
