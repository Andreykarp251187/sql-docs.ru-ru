---
title: Отладка и диагностика приложений Spark
titleSuffix: SQL Server big data clusters
description: Используйте сервер журнала Spark для отладки и диагностики приложений Spark, Spark в кластерах SQL Server 2019 больших данных.
author: jejiang
ms.author: jejiang
ms.reviewer: mikeray
manager: jroth
ms.date: 12/06/2018
ms.topic: conceptual
ms.prod: sql
ms.technology: big-data-cluster
ms.openlocfilehash: cba788fcb61dddce54d8b0c4ad4f2ca87ea0906d
ms.sourcegitcommit: e0c55d919ff9cec233a7a14e72ba16799f4505b2
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/10/2019
ms.locfileid: "67728400"
---
# <a name="debug-and-diagnose-spark-applications-on-sql-server-big-data-clusters-in-spark-history-server"></a>Отладка и диагностика приложений Spark в кластерах больших данных SQL Server в сервер журнала Spark

[!INCLUDE[tsql-appliesto-ssver15-xxxx-xxxx-xxx](../includes/tsql-appliesto-ssver15-xxxx-xxxx-xxx.md)]

Статья содержит рекомендации о том, как использовать расширенные сервер журнала Spark для отладки и диагностики приложений Spark в кластере SQL Server 2019 (Предварительная версия) больших данных. Эти возможности отладки и диагностики встроенные в сервер журнала Spark и на платформе Майкрософт. Расширение включает в себя, вкладка "данные" и вкладки graph и диагностики. На вкладке "данные" пользователям можно проверить входные и выходные данные задания Spark. На вкладке "диаграммы" позволяет проверить поток данных и воспроизвести графа задания. На вкладке "Диагностика" пользователь может ссылаться неравномерное распределение данных, разница во времени и анализ сведений об использовании исполнителя.

## <a name="get-access-to-spark-history-server"></a>Получить доступ к серверу журнала Spark

Интерфейс пользователя сервера журнала Spark с открытым исходным кодом дополнено сведения, которые включают данные относятся к конкретному заданию и интерактивная визуализация потоки данных и граф задания, для больших данных кластера. 

### <a name="open-the-spark-history-server-web-ui-by-url"></a>Откройте веб-сервера журнала Spark пользовательского интерфейса с URL-адрес
Открыть сервер журнала Spark, перейдя к следующему URL-АДРЕСУ, замените `<Ipaddress>` и `<Port>` со сведениями об определенном кластере больших данных. Дополнительные сведения можно обращаться к: [Развертывание кластера больших данных в SQL Server](quickstart-big-data-cluster-deploy.md)

```
https://<Ipaddress>:<Port>/gateway/default/sparkhistory
```

Сервер журнала Spark веб-Интерфейс выглядит:

![Сервер журнала Spark](./media/apache-azure-spark-history-server/spark-history-server.png)


## <a name="data-tab-in-spark-history-server"></a>На вкладке данные сервера журнала Spark
Выберите идентификатор задания, а затем нажмите кнопку **данных** в меню "средства" для получения представления данных.

+ Проверьте **входные данные**, **выходные данные**, и **операций с таблицами** , выбрав на вкладках отдельно.

    ![Вкладки данных сервер журнала Spark](./media/apache-azure-spark-history-server/sparkui-data-tabs.png)

+ Копирование всех строк, нажав кнопку **копирования**.

    ![Копирование всех строк](./media/apache-azure-spark-history-server/sparkui-data-copy.png)

+ Сохранять все данные в виде CSV-файл, нажав кнопку **csv**.

    ![Сохранение данных в виде CSV-файлы](./media/apache-azure-spark-history-server/sparkui-data-save.png)

+ Поиск, введя ключевые слова в поле **поиска**, немедленно отобразится результат поиска.

    ![Поиск с ключевыми словами](./media/apache-azure-spark-history-server/sparkui-data-search.png)

+ Щелкните заголовок столбца для сортировки таблицы, щелкните знак «плюс», чтобы развернуть строку для отображения дополнительных сведений или щелкните знак «минус», чтобы свернуть строку.

    ![Функциональные возможности таблиц данных](./media/apache-azure-spark-history-server/sparkui-data-table.png)

+ Скачивание одного файла, нажав кнопку **частичной загрузки** , поместите справа, то выбранный файл загружается на локальный месте. Если файл больше не существует, откроется новая вкладка для отображения сообщения об ошибках.

    ![Загрузить строку данных](./media/apache-azure-spark-history-server/sparkui-data-download-row.png)

+ Скопируйте полный или относительный путь, выбрав **Копировать полный путь**, **Копировать относительный путь** это развернет окно, в меню загрузки. Для файлов хранилища Озера данных azure **открыть в обозревателе службы хранилища Azure** запустит обозреватель службы хранилища Azure. И найдите папку точное, при входе в систему.

    ![Скопируйте полный или относительный путь](./media/apache-azure-spark-history-server/sparkui-data-copy-path.png)

+ Щелкните номер, указанный ниже таблицы для перехода страниц, когда слишком много строк для отображения на одной странице. 

    ![Страница данных](./media/apache-azure-spark-history-server/sparkui-data-page.png)

+ Наведите указатель мыши на вопросительный знак рядом с полем данных, чтобы увидеть подсказку, или щелкните вопросительный знак для получения дополнительных сведений.

    ![Данные Дополнительные сведения](./media/apache-azure-spark-history-server/sparkui-data-more-info.png)

+ Отправить отзыв с проблемами, щелкнув **отзыв**.

    ![отзыв Graph](./media/apache-azure-spark-history-server/sparkui-graph-feedback.png)

## <a name="graph-tab-in-spark-history-server"></a>График на вкладке сервер журнала Spark

Выберите идентификатор задания, а затем нажмите кнопку **Graph** в меню "средства" для получения представления графика задания.

+ Проверьте сведения о задании, граф созданного задания. 

+ По умолчанию, он будет отображать все задания и может фильтроваться по критериям **идентификатор задания**.

    ![Идентификатор графа задания](./media/apache-azure-spark-history-server/sparkui-graph-jobid.png)

+ Мы оставили **ход выполнения** как значение по умолчанию. Пользователь может проверить поток данных, выбрав **чтения** или ** создано *** в раскрывающемся списке **отображения**.

    ![диаграмме](./media/apache-azure-spark-history-server/sparkui-graph-display.png)

    Отображения узла графа в цвет, который показывает тепловой карты.

    ![граф тепловой карты](./media/apache-azure-spark-history-server/sparkui-graph-heatmap.png)

+ Воспроизведение задания, щелкнув **воспроизведения** кнопку и остановить в любое время, нажав кнопку "Остановить". Отображение задач в цвет для отображения разных состояния, при воспроизведении:

    + Зеленый, при успешном выполнении: Задание успешно завершена.
    + Повторено оранжевый для: Экземпляры задач, которые не удалось, но не влияют на результат задания. Эти задачи было дублирующиеся или повторные экземпляры, которые может завершиться успешно позже.
    + Синий для запуска: Задача выполняется.
    + Белый ожидания или пропущенных: Задача ожидает выполнения или пропущен рабочей области.
    + Не удалось красный для: Задачу не удалось.

    ![Образец цвета диаграммы, под управлением](./media/apache-azure-spark-history-server/sparkui-graph-color-running.png)
 
    Отображение пропущенных этап белого цвета.
    ![Образец цвета графа, пропустить](./media/apache-azure-spark-history-server/sparkui-graph-color-skip.png)

    ![Образец цвета графа, не удалось](./media/apache-azure-spark-history-server/sparkui-graph-color-failed.png)
 
    > [!NOTE]
    > Допускается воспроизведения для каждого задания. Для неполное задание воспроизведение не поддерживается.


+ Прокручивает мыши zoom in/out граф задания, или нажмите кнопку **вписать** чтобы сделать его по размеру экрана.
 
    ![Масштаб графика в соответствии с](./media/apache-azure-spark-history-server/sparkui-graph-zoom2fit.png)

+ Наведите указатель мыши на узел графа, чтобы увидеть, что всплывающей подсказки при наличии невыполненных задач и нажмите кнопку в рабочей области, чтобы открыть страницу рабочей области.

    ![График tooltip](./media/apache-azure-spark-history-server/sparkui-graph-tooltip.png)

+ На вкладке граф задания, будет иметь этапы, подсказки и небольшой значок, отображаемый при наличии задач, которые соответствуют ниже условия:
    + Неравномерное распределение данных: чтение данных размером > размер всех задач внутри этого этапа чтения среднего значения данных * 2 и чтение данных размером 10 МБ >
    + Временное отклонение: время выполнения > среднее время выполнения всех задач внутри этого этапа * 2 и > 2 минут времени выполнения

    ![Наклон значком графика](./media/apache-azure-spark-history-server/sparkui-graph-skew-icon.png)

+ Узел графа задания будет отображаться следующие сведения из каждого этапа:
    + ID.
    + Имя или описание.
    + Номер задачи.
    + Чтение данных: размер чтения сумма значений размер входных данных и случайного распространения.
    + Запись данных: сумма значений размер выходных данных и shuffle размер записи.
    + Время выполнения: время между первой попытки время начала и время завершения последней попытки.
    + Количество строк: Сумма входных записей выходные записи, в случайном порядке считывания записей и записи записей в случайном порядке.
    + Ход выполнения.

    > [!NOTE]
    > По умолчанию узел графа задания будет отображать данные из последней попытки из каждого этапа (за исключением времени выполнения в рабочей области), но во время воспроизведения graph узла будут отображаться сведения о каждой попытки.

    > [!NOTE]
    > Для размер данных для чтения и записи, мы используем 1 МБ = 1000 КБ = 1000 * 1000 байт.

+ Отправить отзыв с проблемами, щелкнув **отзыв**.

    ![отзыв Graph](./media/apache-azure-spark-history-server/sparkui-graph-feedback.png)


## <a name="diagnosis-tab-in-spark-history-server"></a>Вкладка диагностики в сервер журнала Spark
Выберите идентификатор задания, а затем нажмите кнопку **диагностики** в меню "средства" для получения задания представление диагностики. Вкладка диагностики содержит **устранения неравномерного смещения данных**, **отклонения во времени**, и **анализ сведений об использовании исполнитель**.
    
+ Проверьте **устранения неравномерного смещения данных**, **отклонения во времени**, и **анализ сведений об использовании исполнитель** , выбрав на вкладках соответственно.

    ![Вкладки диагностики](./media/apache-azure-spark-history-server/sparkui-diagnosis-tabs.png)

### <a name="data-skew"></a>Неравномерное распределение данных
Нажмите кнопку **устранения неравномерного смещения данных** вкладке соответствующего неравномерные задачи отображаются в зависимости от указанных параметров. 

+ **Укажите параметры** -в первом разделе отображается параметры, которые используются для обнаружения устранения неравномерного смещения данных. Имеет встроенные правила: Считанных данных задач больше, чем три раза среднее задач данные, считанные и считывание данных задачи не более чем 10 МБ. Если вы хотите определить собственные правила для наклона задачи, можно выбрать параметры, **неравномерным этап**, и **наклон Char** раздел будет обновлен соответствующим образом. 

+ **Наклоненный этап** — во втором разделе отображаются этапы, которые содержать смещенные задач, соответствующих критериям, указанным выше. Если имеется более одной задачи неравномерные этапа, в таблице этап с отклонением отображаются только наиболее неравномерные задачи (например, наибольшее данные для неравномерного распределения данных). 

    ![Раздел 2 устранения неравномерного смещения данных](./media/apache-azure-spark-history-server/sparkui-diagnosis-dataskew-section2.png)

+ **Наклон диаграммы** - при выборе строки в таблице неравномерного распределения рабочей области отображения неравномерного распределения на диаграмме Дополнительные сведения о задаче дистрибутивы на основе данных, считанных и время выполнения. Неравномерные задачи помечены красным цветом и обычным задачам помеченные синим цветом. Из соображений производительности на диаграмме отображаются только до 100 образец задач. В нижней правой панели отображаются сведения о задаче.

    ![Section3 устранения неравномерного смещения данных](./media/apache-azure-spark-history-server/sparkui-diagnosis-dataskew-section3.png)

### <a name="time-skew"></a>Разница во времени
**Отклонения во времени** вкладке отображаются неравномерные задачи, на основе времени выполнения задачи. 

+ **Укажите параметры** -в первом разделе отображается параметры, которые используются для определения отклонения во времени. Является критериям по умолчанию для обнаружения неравномерным распределением времени: время выполнения задачи больше, чем три раза из среднее время выполнения и время выполнения задачи больше, чем 30 секунд. Можно изменить параметры в соответствии с потребностями. **Неравномерным этап** и **наклон диаграммы** так же, как отобразить соответствующие этапы и сведения о задачах **устранения неравномерного смещения данных** вкладкой.

+ Нажмите кнопку **отклонения во времени**, то отфильтрованный результат отображается в **неравномерным этап** разделе согласно параметрам, заданным в разделе **Указание параметров**. Выберите один элемент в **неравномерным этап** раздела, то соответствующая диаграмма является черновиком в section3, а на нижней правой панели отображаются сведения о задаче.

    ![Раздел 2 отклонения во времени](./media/apache-azure-spark-history-server/sparkui-diagnosis-timeskew-section2.png)

### <a name="executor-usage-analysis"></a>Анализ сведений об использовании исполнителя
На графике использования исполнителя визуализирует Spark исполнитель выделения и запуска состояние задания.  

+ Нажмите кнопку **анализ сведений об использовании исполнитель**, а затем мы черновик четырех типов кривых об использовании исполнителя. Они включают в себя **выделенных исполнителей**, **под управлением исполнителей**, **простоя исполнителей**, и **максимальное число экземпляров исполнителя**. О выделенных исполнителей каждой «Добавлен исполнителя» или «Удалены исполнителя» события будет увеличиваться или уменьшаться выделенный исполнителей. Вы можете проверить «Временная шкала событий» на вкладке «Задания» для дополнительные сравнения.

    ![Вкладка исполнителей](./media/apache-azure-spark-history-server/sparkui-diagnosis-executors.png)

+ Щелкните значок цвета, чтобы установить или снять соответствующий содержимое всех черновики.

    ![Выберите диаграмму](./media/apache-azure-spark-history-server/sparkui-diagnosis-select-chart.png)


## <a name="known-issues"></a>Известные проблемы
Сервер журнала Spark имеет следующие известные проблемы:

+ В настоящее время он работает только для кластера Spark 2.3.

+ Входные и выходные данные с помощью устойчивого распределенного набора данных не будет отображаться на вкладке "данные".

## <a name="next-steps"></a>Следующие шаги

* [Управление ресурсами для кластера Spark в HDInsight](https://docs.microsoft.com/azure/hdinsight/spark/apache-spark-resource-manager)
* [Настройка параметров Spark](https://docs.microsoft.com/azure/hdinsight/spark/apache-spark-settings)
