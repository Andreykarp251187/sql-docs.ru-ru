---
title: Настройка распределения по уровням HDFS
titleSuffix: SQL Server big data clusters
description: В этой статье объясняется, как настроить уровни HDFS для подключения внешней Azure Data Lake Storage файловой системы к HDFS в [!INCLUDE[big-data-clusters-2019](../includes/ssbigdataclusters-ver15.md)].
author: nelgson
ms.author: negust
ms.reviewer: mikeray
ms.date: 08/21/2019
ms.topic: conceptual
ms.prod: sql
ms.technology: big-data-cluster
ms.openlocfilehash: c7b24af0b0c6a22cbab1a9c280a0ba868ca2cd21
ms.sourcegitcommit: 5e838bdf705136f34d4d8b622740b0e643cb8d96
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/20/2019
ms.locfileid: "69652328"
---
# <a name="configure-hdfs-tiering-on-includebig-data-clusters-2019includesssbigdataclusters-ss-novermd"></a>Настройка уровней HDFS на[!INCLUDE[big-data-clusters-2019](../includes/ssbigdataclusters-ss-nover.md)]

[!INCLUDE[tsql-appliesto-ssver15-xxxx-xxxx-xxx](../includes/tsql-appliesto-ssver15-xxxx-xxxx-xxx.md)]

Распределение по уровням HDFS дает возможность подключить внешнюю файловую систему, совместимую с HDFS, к HDFS. В этой статье описывается настройка уровней HDFS для [!INCLUDE[big-data-clusters-2019](../includes/ssbigdataclusters-ver15.md)] (Предварительная версия). В настоящее время мы поддерживаем подключение к Azure Data Lake Storage 2-го поколения и Amazon S3. 

## <a name="hdfs-tiering-overview"></a>Общие сведения о распределении по уровням HDFS

Благодаря распределению по уровням приложения могут легко получать доступ к данным в различных внешних хранилищах так, как будто данные находятся в локальной системе HDFS. Подключение — это операция с метаданными, предполагающая копирование метаданных, описывающих пространство имен во внешней файловой системе, в локальную систему HDFS. Метаданные включают в себя сведения о внешних каталогах и файлах, а также их разрешения и списки управления доступом. Соответствующие данные копируются по требованию, когда к ним осуществляется доступ, например с помощью запроса. К данным во внешней файловой системе теперь можно обращаться из кластера больших данных SQL Server. Вы можете выполнять задания Spark и запросы SQL к этим данным так же, как к любым локальным данным, хранящимся в системе HDFS в кластере.

### <a name="caching"></a>Кэширование
В настоящее время 1 % общего объема хранилища HDFS по умолчанию резервируется для кэширования подключенных данных. Кэширование настраивается глобально для всех подключенных ресурсов.

> [!NOTE]
> Распределение по уровням HDFS — это функция, разработанная корпорацией Майкрософт. Ее более ранняя версия была выпущена в составе дистрибутива Apache Hadoop 3.1. Подробные сведения см. на странице [https://issues.apache.org/jira/browse/HDFS-9806](https://issues.apache.org/jira/browse/HDFS-9806).

В следующих разделах приводится пример настройки распределения по уровням HDFS для источника данных Azure Data Lake Storage 2-го поколения.

## <a name="refresh"></a>Обновить

Распределение по уровням HDFS поддерживает обновление. Обновите существующий подключенный ресурс, чтобы получить последний моментальный снимок удаленных данных.

## <a name="prerequisites"></a>Предварительные требования

- [Развернутый кластер больших данных](deployment-guidance.md)
- [Средства работы с большими данными](deploy-big-data-tools.md)
  - **azdata**
  - **kubectl**

## <a name="mounting-instructions"></a>Инструкции по подключению

Мы поддерживаем подключение к Azure Data Lake Storage 2-го поколения и Amazon S3. Инструкции по подключению для этих типов хранилища см. в следующих статьях:

- [Подключение ADLS 2-го поколения для распределения по уровням HDFS в кластере больших данных](hdfs-tiering-mount-adlsgen2.md)
- [Подключение S3 для распределения по уровням HDFS в кластере больших данных](hdfs-tiering-mount-s3.md)

## <a id="issues"></a> Известные проблемы и ограничения

В следующем списке приведены известные проблемы и текущие ограничения при использовании уровней HDFS в [!INCLUDE[big-data-clusters-2019](../includes/ssbigdataclusters-ss-nover.md)].

- Если подключенный ресурс долго остается в состоянии `CREATING`, скорее всего, произошел сбой. В этом случае отмените команду и при необходимости удалите подключенный ресурс. Перед повторной попыткой проверьте правильность параметров и учетных данных.

- Подключенные ресурсы нельзя создавать в существующих каталогах.

- Подключенные ресурсы нельзя создавать в существующих подключенных ресурсах.

- Если какие-либо из предков точки подключения не существуют, они будут созданы с разрешениями по умолчанию r-xr-xr-x (555).

- Создание подключения может потребовать некоторого времени в зависимости от количества и размера подключаемых файлов. Во время этого процесса файлы в подключаемом ресурсе не доступны пользователям. Во время создания подключаемого ресурса все файлы добавляются во временную папку, которая по умолчанию находится по пути `/_temporary/_mounts/<mount-location>`.

- Команда создания подключаемого ресурса выполняется асинхронно. После выполнения команды можно проверить состояние подключаемого ресурса.

- При создании подключаемого ресурса аргумент, используемый для **--mount-path**, представляет собой уникальный идентификатор подключаемого ресурса. В последующих командах следует использовать ту же строку (включая символ "/" в конце, если он имеется).

- Подключаемые ресурсы доступны только для чтения. В подключаемом ресурсе нельзя создавать каталоги или файлы.

- Мы не рекомендуем подключать каталоги или файлы, которые могут меняться. После создания подключаемого ресурса любые изменения, вносимые в удаленном расположении, не отражаются в подключаемом ресурсе в HDFS. Если в удаленном расположении есть изменения, вы можете удалить и повторно создать подключаемый ресурс, чтобы обновить состояние.

## <a name="next-steps"></a>Следующие шаги

Дополнительные сведения о [!INCLUDE[big-data-clusters-2019](../includes/ssbigdataclusters-ver15.md)]см. в разделе [что [!INCLUDE[big-data-clusters-2019](../includes/ssbigdataclusters-ver15.md)]такое?](big-data-cluster-overview.md).
