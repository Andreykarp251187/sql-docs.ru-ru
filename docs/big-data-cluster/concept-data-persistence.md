---
title: Сохраняемость данных в Kubernetes
titleSuffix: SQL Server big data clusters
description: Узнайте, как работает сохранение данных в кластере больших данных SQL Server 2019.
author: mihaelablendea
ms.author: mihaelab
ms.reviewer: mikeray
ms.date: 07/24/2019
ms.topic: conceptual
ms.prod: sql
ms.technology: big-data-cluster
ms.openlocfilehash: 9142836032acc5e302c947e1619d17b07faff683
ms.sourcegitcommit: 1f222ef903e6aa0bd1b14d3df031eb04ce775154
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/23/2019
ms.locfileid: "68419471"
---
# <a name="data-persistence-with-sql-server-big-data-cluster-on-kubernetes"></a>Сохраняемость данных с помощью SQL Server кластера больших данных в Kubernetes

[!INCLUDE[tsql-appliesto-ssver15-xxxx-xxxx-xxx](../includes/tsql-appliesto-ssver15-xxxx-xxxx-xxx.md)]

[Постоянные тома](https://kubernetes.io/docs/concepts/storage/persistent-volumes/) предоставляют модель подключаемого модуля для хранения в Kubernetes. Предоставляемое хранилище является абстрактным от того, как оно потребляется. Поэтому вы можете подключить собственное хранилище высокой доступности и подключить его к кластеру SQL Server больших данных. Это позволяет получить полный контроль над типом хранилища, доступности и производительности, которые вам требуются. Kubernetes поддерживает различные типы решений для хранения данных, включая диски и файлы Azure, NFS, локальное хранилище и многое другое.

## <a name="configure-persistent-volumes"></a>Настройка постоянных томов

Способ, которым SQL Server кластер больших данных использует эти постоянные тома, — это использование [классов хранения](https://kubernetes.io/docs/concepts/storage/storage-classes/). Вы можете создать различные классы хранения для хранилища различных типов и указать их в ходе развертывания кластера больших данных. Вы можете настроить класс хранения и размер постоянного тома, которые будут использоваться для этой цели на уровне пула. SQL Server кластер больших данных создает [постоянные утверждения томов](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims) с указанным именем класса хранения для каждого компонента, для которого требуются постоянные тома. Затем он подключает соответствующие постоянные тома в Pod. 

## <a name="configure-big-data-cluster-storage-settings"></a>Настройка параметров хранилища кластера больших данных

Аналогично другим настройкам можно указать параметры хранилища в файлах конфигурации кластера во время развертывания для каждого пула и плоскости управления. Если в спецификациях пула нет параметров конфигурации хранилища, будут использоваться параметры хранилища плоскости управления. Ниже приведен пример раздела конфигурации хранилища, который можно включить в спецификацию:

```json
    "storage": 
    {
      "data": {
        "className": "default",
        "accessMode": "ReadWriteOnce",
        "size": "15Gi"
      },
      "logs": {
        "className": "default",
        "accessMode": "ReadWriteOnce",
        "size": "10Gi"
    }
```

Развертывание кластера больших данных будет использовать постоянное хранилище для хранения данных, метаданных и журналов для различных компонентов. Можно настроить размер утверждений Постоянного тома, создаваемых в ходе развертывания. Рекомендуется использовать классы хранения со строгой политикой *сохранения* [заявок](https://kubernetes.io/docs/concepts/storage/storage-classes/#reclaim-policy).

> [!NOTE]
> В CTP-версии 3,2 нельзя изменить параметр конфигурации хранилища после развертывания. Кроме того, `ReadWriteOnce` поддерживается только режим доступа для всего кластера.

> [!WARNING]
> Запуск без постоянного хранилища может работать в тестовой среде, но может привести к нефункциональному кластеру. При перезапуске Pod метаданные кластера и (или) пользовательские данные будут утеряны без возможности восстановления. Не рекомендуется выполнять в этой конфигурации. 

В разделе [Настройка хранилища](#config-samples) приведены дополнительные примеры настройки параметров хранилища для SQL Server развертывания кластера больших данных.

## <a name="aks-storage-classes"></a>Классы хранения AKS

AKS поставляется с [двумя встроенными классами хранения](https://docs.microsoft.com/azure/aks/azure-disks-dynamic-pv) **по умолчанию** и " **управляемый — премиум** " вместе с динамическим подготовкой для них. Вы можете указать любой из них или создать собственный класс хранения для развертывания кластера больших данных с включенным постоянным хранилищем. По умолчанию встроенный файл конфигурации кластера для AKS *AKS-dev-test* поставляется с постоянными конфигурациями хранилища для использования класса хранения **по умолчанию** .

> [!WARNING]
> Постоянные тома, созданные с помощью встроенных классов хранения **по умолчанию** и **Managed-Premium** , имеют политику отмены утверждения для *удаления*. Поэтому, когда вы удаляете SQL Server кластер больших данных, утверждения Постоянного тома удаляются, а затем сохраняются на томах. Вы можете создать пользовательские классы хранения, используя **Azure-Disk** привионер с политикой *сохранения* заявок, как показано в [этой](https://docs.microsoft.com/en-us/azure/aks/concepts-storage#storage-classes) статье.


## <a name="minikube-storage-class"></a>Класс хранения Minikube

Minikube поставляется со встроенным классом хранения, именуемым **Standard** , и динамическим подготовкой. Встроенный файл конфигурации для minikube *minikube-dev-test* содержит параметры конфигурации хранилища в спецификации плоскости управления. Те же параметры будут применяться ко всем спецификациям пулов. Кроме того, можно настроить копию этого файла и использовать его для развертывания кластера больших данных на minikube. Вы можете вручную изменить пользовательский файл и изменить размер заявок на постоянные тома для конкретных пулов, чтобы они соответствовали рабочим нагрузкам, которые необходимо выполнить. Также см. Дополнительные сведения о том, как выполнять изменения с помощью команд *аздата* . в разделе [Настройка хранилища](#config-samples) .

## <a name="kubeadm-storage-classes"></a>Классы хранения кубеадм

Кубеадм не поставляется со встроенным классом хранения. Необходимо создать собственные классы хранения и постоянные тома с помощью локального хранилища или предпочтительного средства подготовки, например [рук](https://github.com/rook/rook). В этом случае необходимо задать для **className** класс хранения, который вы настроили. 

> [!NOTE]
>  В файле конфигурации встроенного развертывания для *кубеадм кубеадм-dev-test* для хранилища данных и журнала не указано имя класса хранения. Перед развертыванием необходимо настроить файл конфигурации и задать значение для className, иначе проверки перед развертыванием завершатся ошибкой. Развертывание также имеет шаг проверки, который проверяет наличие класса хранения, но не для необходимых постоянных томов. Необходимо убедиться в том, что вы создали достаточно томов в зависимости от масштаба кластера. В CTP 3,1 для размера кластера по умолчанию необходимо создать не менее 23 томов. [Ниже](https://github.com/Microsoft/sql-server-samples/tree/master/samples/features/sql-big-data-cluster/deployment/kubeadm/ubuntu) приведен пример создания постоянных томов с помощью локального средства подготовки.


## <a name="customize-storage-configurations-for-each-pool"></a>Настройка конфигураций хранилища для каждого пула

Для всех настроек необходимо сначала создать копию встроенного файла конфигурации, который вы хотите использовать. Например, следующая команда создает копию файлов конфигурации развертывания *AKS-dev-test* в подкаталоге с именем `custom`:

```bash
azdata bdc config init --source aks-dev-test --target custom
```

При этом создаются два файла: **cluster. JSON** и **Control. JSON** , которые можно настроить путем редактирования вручную, или можно использовать команду **аздата BDC config** . Вы можете использовать сочетание библиотек jsonpath и жсонпатч, чтобы предоставить способы изменения файлов конфигурации.


### <a id="config-samples"></a>Настройка имени класса хранения и/или размера утверждений

По умолчанию размер постоянных томов, подготовленных для каждого из модулей Pod, подготовленных в кластере, составляет 10 ГБ. Это значение можно изменить для размещения рабочих нагрузок, выполняемых в пользовательском файле конфигурации, перед развертыванием кластера.

В следующем примере изменяется размер постоянного объема заявок на 32Gi в **элементе управления. жсаон**. Если он не переопределен на уровне пула, этот параметр будет применен ко всем пулам:

```bash
azdata bdc config replace --config-file custom/control.json --json-values "$.spec.storage.data.size=100Gi"
```

В следующем примере показано, как изменить класс хранения для файла **Control. JSON** :

```bash
azdata bdc config replace --config-file custom/control.json --json-values "$.spec.storage.data.className=<yourStorageClassName>"
```

Кроме того, можно вручную изменить пользовательский файл конфигурации или использовать исправление JSON, как в следующем примере, который изменяет класс хранения для пула носителей. Создайте файл *patch. JSON* с этим содержимым:

```json
{
  "patch": [
    {
      "op": "replace",
      "path": "$.spec.pools[?(@.spec.type == 'Storage')].spec.storage"
      "value": {
          "type":"Storage",
          "replicas":2,
          "data": {
            "className": "default",
            "accessMode": "ReadWriteOnce",
            "size": "100Gi"
          },
          "logs": {
            "className": "default",
            "accessMode": "ReadWriteOnce",
            "size": "32Gi"
          }
        }
      }
  ]
}
```

Примените файл исправления. Используйте команду **аздата BDC config Patch** , чтобы применить изменения в файле исправления JSON. В следующем примере файл patch. JSON применяется к целевому файлу конфигурации развертывания Custom. JSON.

```bash
azdata bdc config patch --config-file custom/cluster.json --patch-file ./patch.json
```

## <a name="next-steps"></a>Следующие шаги

Полную документацию по томам в Kubernetes см. в [документации Kubernetes по томам](https://kubernetes.io/docs/concepts/storage/volumes/).

Дополнительные сведения о развертывании SQL Server кластера больших данных см. в статье [развертывание SQL Server кластера больших данных в Kubernetes](deployment-guidance.md).

