---
title: Сохраняемость данных в Kubernetes
titleSuffix: SQL Server big data clusters
description: Узнайте, как реализуется сохраняемость данных в кластере больших данных SQL Server 2019.
author: mihaelablendea
ms.author: mihaelab
ms.reviewer: mikeray
ms.date: 11/04/2019
ms.topic: conceptual
ms.prod: sql
ms.technology: big-data-cluster
ms.openlocfilehash: 34599160e206d89eaee04074ddbaee2bac7c5f89
ms.sourcegitcommit: 9bdecafd1aefd388137ff27dfef532a8cb0980be
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 02/12/2020
ms.locfileid: "77173570"
---
# <a name="data-persistence-with-sql-server-big-data-cluster-in-kubernetes"></a>Сохраняемость данных при использовании кластера больших данных SQL Server в Kubernetes

[!INCLUDE[tsql-appliesto-ssver15-xxxx-xxxx-xxx](../includes/tsql-appliesto-ssver15-xxxx-xxxx-xxx.md)]

[Постоянные тома](https://kubernetes.io/docs/concepts/storage/persistent-volumes/) предоставляют модель подключения для хранилища в Kubernetes. В этой модели способ предоставления хранилища абстрагируется от его использования. Поэтому вы можете подключить собственное хранилище высокого уровня доступности к кластеру больших данных SQL Server. Это позволяет получить полный контроль над типом хранилища, доступностью и производительностью. Kubernetes поддерживает [различные типы решений для хранения данных](https://kubernetes.io/docs/concepts/storage/storage-classes/#provisioner), включая диски и файлы Azure, NFS и локальное хранилище.

## <a name="configure-persistent-volumes"></a>Настройка постоянных томов

Постоянные тома используются в кластере больших данных SQL Server посредством [классов хранения](https://kubernetes.io/docs/concepts/storage/storage-classes/). Вы можете создать различные классы хранения для хранилищ разных типов и указать их во время развертывания кластера больших данных. Вы также можете указать класс хранения и размер требования постоянного тома, которые должны использоваться в конкретных целях на уровне пула. Кластер больших данных SQL Server создает [утверждения постоянных томов](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims) с помощью указанного имени класса хранения для каждого компонента, которому требуются постоянные тома. Затем он подключает соответствующий постоянный том (или тома) в объекте pod. 

Ниже приведены некоторые важные аспекты, которые следует учитывать при планировании конфигурации хранилища для кластера больших данных:

- Для успешного развертывания кластера больших данных убедитесь, что доступно необходимое количество постоянных томов. Если вы выполняете развертывание в кластере Службы Azure Kubernetes (AKS) и используете встроенный класс хранилища (`default` или `managed-premium`), этот класс поддерживает динамическую подготовку постоянных томов. Поэтому вам не нужно предварительно создавать постоянные тома, но необходимо убедиться, что к рабочим узлам в кластере AKS можно подключить столько дисков, сколько постоянных томов необходимо для развертывания. В зависимости от [размера виртуальной машины](https://docs.microsoft.com/azure/virtual-machines/linux/sizes), заданной для рабочих узлов, к каждому узлу можно подключить определенное количество дисков. Для кластера размером по умолчанию (без высокой доступности) требуется не менее 24 дисков. Если вы включаете для пула высокий уровень доступности или масштабируете его, убедитесь, что у вас есть как минимум два постоянных тома на каждую дополнительную реплику независимо от ресурса, для которого выполняется масштабирование.

- Если средство подготовки хранилища для класса хранения, который вы задаете в конфигурации, не поддерживает динамическую подготовку, необходимо создать постоянные тома заранее. Так, средство подготовки `local-storage` не включает динамическую подготовку. В этом [примере скрипта](https://github.com/microsoft/sql-server-samples/tree/master/samples/features/sql-big-data-cluster/deployment/kubeadm/ubuntu) вы найдете рекомендации по выполнению этого действия в кластере Kubernetes, развертываемом с помощью `kubeadm`.

- При развертывании кластера больших данных можно настроить один класс хранения для использования всеми компонентами в кластере. Однако для развертывания в производственной среде рекомендуется назначать разным компонентам разные конфигурации хранения, чтобы удовлетворить потребности разных рабочих нагрузок с точки зрения размера или пропускной способности. Вы можете перезаписать конфигурацию хранилища по умолчанию, заданную в контроллере для каждого основного экземпляра SQL Server, набора данных и пула носителей. В этой статье приводятся примеры того, как это сделать.

- Начиная с выпуска SQL Server 2019 CU1 изменить параметры конфигурации хранилища после развертывания невозможно. Из-за этого ограничения невозможно не только изменить заявленный размер постоянного тома для каждого экземпляра, но и масштабировать систему после развертывания. Поэтому очень важно спланировать структуру хранилища перед развертыванием кластера больших данных.

- С помощью развертывания в Kubernetes в качестве контейнерных приложений и использования таких функций, как наборы с отслеживанием состояния и постоянное хранилище, Kubernetes гарантирует, что объекты pod перезапускаются в случае проблем с работоспособностью и подключаются к тому же постоянному хранилищу. Однако в случае сбоя узла и необходимости перезапустить pod на другом узле возрастает риск недоступности системы, если использовалось локальное по отношению к вышедшему из строя узлу хранилище. Чтобы уменьшить такой риск, необходимо либо настроить дополнительное резервирование и включить [компоненты обеспечения высокой доступности](deployment-high-availability.md), либо использовать удаленное хранилище с резервированием. Ниже приведен обзор вариантов хранилищ для различных компонентов в кластерах больших данных:

| Ресурсы | Тип хранилища для данных | Тип хранилища для журнала |  Примечания |
|---|---|---|--|
| Главный экземпляр SQL Server | Локальное (не менее 3 реплик) или удаленное хранилище с резервированием (1 реплика) | Локальное хранилище | Реализация на основе набора с отслеживанием состояния, в которой объекты pod связаны с узлами, защитит от потери данных при перезапусках и в случае временных сбоев. |
| Вычислительный пул | Локальное хранилище | Локальное хранилище | Данные пользователей не хранятся. |
| Пул данных | Локальное или удаленное хранилище с резервированием | Локальное хранилище | Используйте удаленное хранилище с резервированием, если не удается перестроить пул данных из других источников.  |
| Пул носителей (HDFS) | Локальное или удаленное хранилище с резервированием | Локальное хранилище | Убедитесь, что репликация включена. |
| Пул Spark | Локальное хранилище | Локальное хранилище | Данные пользователей не хранятся. |
| Управление (controldb, metricsdb, logsdb)| Удаленное хранилище с резервированием | Локальное хранилище | Очень важно использовать резервирование на уровне хранилища для метаданных кластера больших данных. |

> [!IMPORTANT]
> Убедитесь, что связанные с управлением компоненты находятся в устройстве удаленного хранилища с резервированием. Объект pod `controldb-0` содержит экземпляр SQL Server с базами данных, где хранятся все метаданные, связанные с состояниями службы кластеров, различными настройками и другой соответствующей информацией. Если экземпляр становится недоступным, это приведет к проблемам с работоспособностью других зависимых служб в кластере.

## <a name="configure-big-data-cluster-storage-settings"></a>Настройка параметров хранилища для кластера больших данных

Так же как и другие настройки, параметры хранилища можно указать в файлах конфигурации кластера во время развертывания для каждого пула в файле конфигурации `bdc.json` и для служб управления в файле `control.json`. Если в спецификациях пула нет параметров конфигурации хранилища, то параметры хранилища управления будут использоваться для всех других компонентов, включая основной экземпляр SQL Server (ресурс `master`), HDFS (ресурс `storage-0`) и компоненты пула данных. Следующий пример кода представляет раздел конфигурации хранилища, который можно включить в спецификацию:

```json
    "storage": 
    {
      "data": {
        "className": "default",
        "accessMode": "ReadWriteOnce",
        "size": "15Gi"
      },
      "logs": {
        "className": "default",
        "accessMode": "ReadWriteOnce",
        "size": "10Gi"
    }
```

Развернутый кластер больших данных использует постоянное хранилище для хранения данных, метаданных и журналов различных компонентов. Вы можете настроить размер утверждений постоянных томов, создаваемых в ходе развертывания. Рекомендуется использовать классы хранения с *политикой освобождения* [Сохранение](https://kubernetes.io/docs/concepts/storage/storage-classes/#reclaim-policy).

> [!WARNING]
> Запуск без постоянного хранилища возможен в тестовой среде, но может привести к утрате работоспособности кластера. При перезапуске объектов pod метаданные кластера и/или пользовательские данные будут утеряны без возможности восстановления. Не рекомендуется работать с этой конфигурацией.

В разделе [Настройка хранилища](#config-samples) приведены дополнительные примеры настройки параметров хранилища для развертывания кластера больших данных SQL Server.

## <a name="aks-storage-classes"></a>Классы хранения AKS

В AKS есть [два встроенных класса хранения](/azure/aks/azure-disks-dynamic-pv/), `default` и `managed-premium`, а также средство динамической подготовки для них. Вы можете выбрать любой из них или создать собственный класс хранения для развертывания кластера больших данных с включенным постоянным хранилищем. По умолчанию встроенный файл конфигурации кластера для AKS `aks-dev-test` содержит конфигурации постоянного хранилища, предусматривающие использование класса хранения `default`.

> [!WARNING]
> Постоянные тома, созданные с помощью встроенных классов хранения `default` и `managed-premium`, имеют политику освобождения *Удаление*. Поэтому при удалении кластера больших данных SQL Server утверждения постоянных томов удаляются, а затем удаляются и сами тома. Вы можете создавать пользовательские классы хранения с помощью средства подготовки `azure-disk` с политикой освобождения `Retain`, как показано в разделе [Классы хранилищ](/azure/aks/concepts-storage/#storage-classes).

## <a name="storage-classes-for-kubeadm-clusters"></a>Классы хранения для кластеров `kubeadm` 

Кластеры Kubernetes, развернутые с помощью `kubeadm`, не имеют встроенного класса хранения. Необходимо создать собственные классы хранения и постоянные тома с помощью локального хранилища или [предпочтительного средства подготовки хранилища](https://kubernetes.io/docs/concepts/storage/storage-classes/#provisioner). В этой ситуации необходимо присвоить свойство `className` настроенному классу хранения.

> [!IMPORTANT]
>  Во встроенных файлах конфигурации развертывания для kubeadm (`kubeadm-dev-test` и `kubeadm-prod`) не указано имя класса хранения для хранилища данных и журналов. Перед развертыванием необходимо настроить файл конфигурации и задать значение для `className`. В противном случае проверки перед развертыванием завершатся ошибкой. Во время развертывания также проверяется наличие класса хранения, но наличие требуемых постоянных томов не проверяется. Создайте достаточно томов в зависимости от размера кластера. Для минимального размера кластера по умолчанию (масштаб по умолчанию, без высокой доступности) необходимо создать не менее 24 постоянных томов. Пример того, как можно создавать постоянные тома с помощью локального средства подготовки, см. в статье о [создании кластера Kubernetes с помощью Kubeadm](https://github.com/Microsoft/sql-server-samples/tree/master/samples/features/sql-big-data-cluster/deployment/kubeadm/ubuntu).

## <a name="customize-storage-configurations-for-each-pool"></a>Настройка конфигураций хранилища для каждого пула

Для любой настройки необходимо сначала создать копию встроенного файла конфигурации, который требуется использовать. Например, следующая команда создает копию файлов конфигурации развертывания `aks-dev-test` в подкаталоге `custom`:

```bash
azdata bdc config init --source aks-dev-test --target custom
```

Этот процесс создает два файла: `bdc.json` и `control.json`, которые можно настроить вручную либо с помощью команды `azdata bdc config`. Для изменения файлов конфигурации можно использовать сочетание библиотек jsonpath и jsonpatch.


### <a id="config-samples"></a> Настройка имени класса хранения и размера утверждений

По умолчанию размер утверждений постоянных томов, подготавливаемых для каждого объекта pod в кластере, составляет 10 гигабайт (ГБ). Это значение можно изменить в соответствии с выполняемыми рабочими нагрузками в пользовательском файле конфигурации перед развертыванием кластера.

В приведенном ниже примере размер утверждений постоянных томов изменяется на 32 ГБ в файле `control.json`. Если этот параметр не переопределен на уровне пула, он применяется ко всем пулам.

```bash
azdata bdc config replace --config-file custom/control.json --json-values "$.spec.storage.data.size=100Gi"
```

В следующем примере показано, как изменить класс хранения для файла `control.json`:

```bash
azdata bdc config replace --config-file custom/control.json --json-values "$.spec.storage.data.className=<yourStorageClassName>"
```

Другой способ — вручную изменить пользовательский файл конфигурации или использовать исправление JSON, в котором изменяется класс хранения для пула носителей, как в приведенном ниже примере:

```json
{
  "patch": [
    {
      "op": "replace",
      "path": "$.spec.resources.storage-0.spec",
      "value": {
        "type":"Storage",
        "replicas":2,
        "storage":{
            "data":{
                    "size": "100Gi",
                    "className": "myStorageClass",
                    "accessMode":"ReadWriteOnce"
                    },
            "logs":{
                    "size":"32Gi",
                    "className":"myStorageClass",
                    "accessMode":"ReadWriteOnce"
                    }
                }
            }
        }
    ]
}
```

Примените файл исправления. Используйте команду `azdata bdc config patch`, чтобы применить эти изменения в файле исправления JSON. В следующем примере файл `patch.json` применяется к целевому файлу конфигурации развертывания `custom.json`:

```bash
azdata bdc config patch --config-file custom/bdc.json --patch-file ./patch.json
```

## <a name="next-steps"></a>Дальнейшие действия

- Полные сведения о томах в Kubernetes см. в [документации Kubernetes по томам](https://kubernetes.io/docs/concepts/storage/volumes/).

- Дополнительные сведения о развертывании кластера больших данных SQL Server см. в статье [Развертывание кластера больших данных SQL Server в Kubernetes](deployment-guidance.md).
